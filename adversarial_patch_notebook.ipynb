{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d82b2655",
   "metadata": {},
   "source": [
    "Adversarial Patch - ResNet34 (Colab/Notebook)\n",
    "\n",
    "I create a targeted adversarial patch for torchvision ResNet34 on a small ImageNet setup. \n",
    "I keep things simple and reproducible. If any cell needs my manual action (e.g., uploading images), I note it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4090e456",
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic imports\n",
    "import os, io, math, random, json, time\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision as tv\n",
    "from torchvision import transforms\n",
    "from PIL import Image, ImageDraw\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# reproducibility\n",
    "def seed_everything(seed=42):\n",
    "    random.seed(seed); np.random.seed(seed); torch.manual_seed(seed); torch.cuda.manual_seed_all(seed)\n",
    "seed_everything(123)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('device:', device)\n",
    "\n",
    "# folders\n",
    "BASE = Path('.').resolve()\n",
    "OUT = BASE / 'outputs'\n",
    "OUT.mkdir(exist_ok=True, parents=True)\n",
    "print('outputs ->', OUT)\n",
    "\n",
    "# small utility to show images inline (tensor in [0,1])\n",
    "def show_tensor_img(t, title=None):\n",
    "    t = t.detach().cpu().clamp(0,1)\n",
    "    if t.ndim == 4:  # show first one\n",
    "        t = t[0]\n",
    "    img = transforms.ToPILImage()(t)\n",
    "    plt.figure(figsize=(3,3))\n",
    "    plt.axis('off')\n",
    "    if title: plt.title(title)\n",
    "    plt.imshow(img)\n",
    "    plt.show()\n",
    "\n",
    "def save_tensor_img(t, path):\n",
    "    t = t.detach().cpu().clamp(0,1)\n",
    "    if t.ndim == 4:\n",
    "        t = t[0]\n",
    "    img = transforms.ToPILImage()(t)\n",
    "    img.save(path)\n",
    "    print('saved', path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b3c1753",
   "metadata": {},
   "source": [
    "Model and classes\n",
    "\n",
    "I load torchvision ResNet34 with ImageNet1K weights. If downloading weights fails (no internet), I fall back to an untrained model so the notebook still runs. For class names, I try to fetch `imagenet_classes.txt`; if it fails, I fall back to index-only labels. If I need a specific class and the list is missing, I can set it by index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c42d522f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model (pretrained if possible)\n",
    "from torchvision.models import resnet34, ResNet34_Weights\n",
    "\n",
    "def load_model_safe():\n",
    "    try:\n",
    "        weights = ResNet34_Weights.IMAGENET1K_V1\n",
    "        model = resnet34(weights=weights).eval().to(device)\n",
    "        preprocess = weights.transforms()\n",
    "        print('Loaded pretrained ResNet34.')\n",
    "        return model, preprocess\n",
    "    except Exception as e:\n",
    "        print('Could not load pretrained weights:', e)\n",
    "        model = resnet34(weights=None).eval().to(device)\n",
    "        # default preprocess to ImageNet stats\n",
    "        preprocess = transforms.Compose([\n",
    "            transforms.Resize(256),\n",
    "            transforms.CenterCrop(224),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "        print('Using untrained model as fallback.')\n",
    "        return model, preprocess\n",
    "\n",
    "model, preprocess = load_model_safe()\n",
    "\n",
    "# class names\n",
    "def load_imagenet_classes():\n",
    "    # try several sources\n",
    "    urls = [\n",
    "        'https://raw.githubusercontent.com/pytorch/hub/master/imagenet_classes.txt',\n",
    "        'https://raw.githubusercontent.com/anishathalye/imagenet-simple-labels/master/imagenet-simple-labels.json'\n",
    "    ]\n",
    "    names = None\n",
    "    import urllib.request, ssl\n",
    "    try:\n",
    "        ctx = ssl.create_default_context()\n",
    "        ctx.check_hostname = False\n",
    "        ctx.verify_mode = ssl.CERT_NONE\n",
    "        txt = None\n",
    "        for u in urls:\n",
    "            try:\n",
    "                with urllib.request.urlopen(u, context=ctx, timeout=10) as r:\n",
    "                    data = r.read()\n",
    "                if u.endswith('.txt'):\n",
    "                    lines = data.decode('utf-8').strip().splitlines()\n",
    "                    if len(lines) >= 1000:\n",
    "                        names = [s.strip() for s in lines]\n",
    "                        break\n",
    "                else:\n",
    "                    arr = json.loads(data.decode('utf-8'))\n",
    "                    if len(arr) >= 1000:\n",
    "                        names = arr\n",
    "                        break\n",
    "            except Exception:\n",
    "                pass\n",
    "    except Exception as e:\n",
    "        names = None\n",
    "    if names is None:\n",
    "        # fallback to index names\n",
    "        names = [f'class_{i}' for i in range(1000)]\n",
    "        print('Could not fetch class names; using index labels.')\n",
    "    else:\n",
    "        print('Loaded ImageNet class names:', len(names))\n",
    "    return names\n",
    "\n",
    "IMAGENET_CLASSES = load_imagenet_classes()\n",
    "\n",
    "# helpers for predictions\n",
    "@torch.no_grad()\n",
    "def topk_preds(logits, k=5):\n",
    "    probs = F.softmax(logits, dim=1)\n",
    "    p, idx = probs.topk(k, dim=1)\n",
    "    return p.cpu().numpy(), idx.cpu().numpy()\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict(model, x):\n",
    "    model.eval()\n",
    "    logits = model(x.to(device))\n",
    "    return logits\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33f7fd50",
   "metadata": {},
   "source": [
    "Target class\n",
    "\n",
    "I choose a target class by name substring. If there are multiple matches, I take the first. If no match, I set it by index. I can change `TARGET_KEYWORD` or `TARGET_INDEX` later and rerun the cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f9a7739",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_KEYWORD = 'toilet tissue'  # free to change, e.g., 'banana', 'pizza', 'goldfish'\n",
    "TARGET_INDEX = None  # if None, resolve from keyword; otherwise override (0..999)\n",
    "\n",
    "def resolve_target_index(keyword, override=None):\n",
    "    if override is not None:\n",
    "        return int(override)\n",
    "    key = (keyword or '').lower().strip()\n",
    "    for i, name in enumerate(IMAGENET_CLASSES):\n",
    "        if key and key in name.lower():\n",
    "            print(f'target -> idx={i}, name={IMAGENET_CLASSES[i]}')\n",
    "            return i\n",
    "    # default: class 859 ('toilet tissue' in common mapping), but fallback may differ\n",
    "    default_idx = 859 if len(IMAGENET_CLASSES) > 859 else 0\n",
    "    print(f'keyword not found; fallback idx={default_idx}, name={IMAGENET_CLASSES[default_idx]}')\n",
    "    return default_idx\n",
    "\n",
    "TARGET = resolve_target_index(TARGET_KEYWORD, TARGET_INDEX)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46db15ec",
   "metadata": {},
   "source": [
    "Images\n",
    "\n",
    "I test on a few pictures. If I am in Colab, I can upload files (jpg/png). If download works, I also fetch 3 sample images. If both fail, I fall back to random colors so the notebook still runs (results will be meaningless, but the code path is safe)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab844cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "RAW = BASE / 'raw_images'\n",
    "RAW.mkdir(exist_ok=True)\n",
    "\n",
    "def in_colab():\n",
    "    try:\n",
    "        import google.colab  # type: ignore\n",
    "        return True\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "def ask_upload():\n",
    "    if in_colab():\n",
    "        from google.colab import files  # type: ignore\n",
    "        print('Choose 1-5 images to upload (jpg/png).')\n",
    "        up = files.upload()\n",
    "        for k, v in up.items():\n",
    "            with open(RAW / k, 'wb') as f:\n",
    "                f.write(v)\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def try_download_samples():\n",
    "    import urllib.request, ssl\n",
    "    urls = [\n",
    "        'https://images.unsplash.com/photo-1518791841217-8f162f1e1131?w=800',  # cat\n",
    "        'https://images.unsplash.com/photo-1507149833265-60c372daea22?w=800',  # dog\n",
    "        'https://images.unsplash.com/photo-1542291026-7eec264c27ff?w=800',    # pizza\n",
    "    ]\n",
    "    ok = 0\n",
    "    try:\n",
    "        ctx = ssl.create_default_context()\n",
    "        ctx.check_hostname = False\n",
    "        ctx.verify_mode = ssl.CERT_NONE\n",
    "        for i,u in enumerate(urls):\n",
    "            p = RAW / f'sample_{i}.jpg'\n",
    "            if p.exists(): \n",
    "                ok += 1; \n",
    "                continue\n",
    "            with urllib.request.urlopen(u, context=ctx, timeout=10) as r:\n",
    "                data = r.read()\n",
    "            with open(p, 'wb') as f:\n",
    "                f.write(data)\n",
    "            ok += 1\n",
    "    except Exception as e:\n",
    "        pass\n",
    "    return ok\n",
    "\n",
    "def fallback_random_images(n=3):\n",
    "    for i in range(n):\n",
    "        arr = np.random.rand(256,256,3).astype(np.float32)\n",
    "        img = Image.fromarray((arr*255).astype(np.uint8))\n",
    "        img.save(RAW / f'random_{i}.png')\n",
    "\n",
    "# ensure we have some images\n",
    "imgs_before = list(RAW.glob('*'))\n",
    "if len(imgs_before) == 0:\n",
    "    uploaded = ask_upload()\n",
    "    if not uploaded:\n",
    "        d = try_download_samples()\n",
    "        if d == 0:\n",
    "            fallback_random_images(3)\n",
    "\n",
    "all_paths = sorted(list(RAW.glob('*')))\n",
    "print('found images:', len(all_paths))\n",
    "for p in all_paths[:5]:\n",
    "    print(' -', p.name)\n",
    "\n",
    "def load_images(paths, max_n=8):\n",
    "    ims = []\n",
    "    for p in paths[:max_n]:\n",
    "        try:\n",
    "            im = Image.open(p).convert('RGB')\n",
    "            ims.append(im)\n",
    "        except Exception:\n",
    "            pass\n",
    "    return ims\n",
    "\n",
    "raw_images = load_images(all_paths, max_n=8)\n",
    "print('loaded images:', len(raw_images))\n",
    "display(raw_images[0] if len(raw_images)>0 else Image.new('RGB',(224,224),(128,128,128)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "083bb55c",
   "metadata": {},
   "source": [
    "Baseline prediction\n",
    "\n",
    "I run the model on the clean images and print top-5. This lets me see what the model thinks before I place any patch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "004419b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_batch(ims):\n",
    "    tensors = []\n",
    "    for im in ims:\n",
    "        t = preprocess(im)\n",
    "        tensors.append(t)\n",
    "    if len(tensors)==0:\n",
    "        # fallback dummy\n",
    "        tensors = [torch.zeros(3,224,224)]\n",
    "    x = torch.stack(tensors, dim=0)\n",
    "    return x\n",
    "\n",
    "x_clean = to_batch(raw_images).to(device)\n",
    "with torch.no_grad():\n",
    "    logits = model(x_clean)\n",
    "probs, idxs = topk_preds(logits, k=5)\n",
    "\n",
    "for i in range(x_clean.shape[0]):\n",
    "    print(f'Image {i}:')\n",
    "    for p, idx in zip(probs[i], idxs[i]):\n",
    "        name = IMAGENET_CLASSES[idx] if idx < len(IMAGENET_CLASSES) else f'class_{idx}'\n",
    "        print(f'  {float(p):.4f} -> {idx}: {name}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87360311",
   "metadata": {},
   "source": [
    "Patch\n",
    "\n",
    "I optimize a square RGB patch (values in [0,1]) and place it randomly on each image. I use a simple differentiable overlay (resize + paste) without rotation to keep it stable. I can tune patch size and steps if I need stronger effect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07351d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# differentiable overlay\n",
    "def place_patch(images01, patch01, frac_min=0.18, frac_max=0.32):\n",
    "    # images01: [N,3,H,W] in [0,1]\n",
    "    N, C, H, W = images01.shape\n",
    "    out = images01.clone()\n",
    "    for i in range(N):\n",
    "        s_frac = random.uniform(frac_min, frac_max)\n",
    "        ph = pw = max(4, int(round(H * s_frac)))\n",
    "        # resize patch\n",
    "        p = F.interpolate(patch01.unsqueeze(0), size=(ph,pw), mode='bilinear', align_corners=True)[0]\n",
    "        # position\n",
    "        y = random.randint(0, H - ph)\n",
    "        x = random.randint(0, W - pw)\n",
    "        # alpha mask (soft edges a bit)\n",
    "        mask = torch.ones_like(p[:1])\n",
    "        # paste\n",
    "        out[i,:,y:y+ph, x:x+pw] = out[i,:,y:y+ph, x:x+pw] * (1-mask) + p * mask\n",
    "    return out\n",
    "\n",
    "def denorm(x):\n",
    "    # inverse of imagenet normalization\n",
    "    mean = torch.tensor([0.485, 0.456, 0.406], device=x.device).view(1,3,1,1)\n",
    "    std  = torch.tensor([0.229, 0.224, 0.225], device=x.device).view(1,3,1,1)\n",
    "    return x * std + mean\n",
    "\n",
    "def norm01(x):\n",
    "    # convert normalized tensor back to [0,1]\n",
    "    return denorm(x).clamp(0,1)\n",
    "\n",
    "# build a [0,1] version of our current clean batch\n",
    "def batch01_from_raw(ims):\n",
    "    # produce [N,3,224,224] in [0,1] (no normalization)\n",
    "    tensors = []\n",
    "    basic = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "    for im in ims:\n",
    "        tensors.append(basic(im))\n",
    "    if len(tensors) == 0:\n",
    "        tensors = [torch.zeros(3,224,224)]\n",
    "    return torch.stack(tensors, 0).to(device)\n",
    "\n",
    "batch01 = batch01_from_raw(raw_images)\n",
    "show_tensor_img(batch01, 'example input [0,1] (first image)')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ad1eaf",
   "metadata": {},
   "source": [
    "Optimize\n",
    "\n",
    "I perform targeted optimization: maximize the model probability for my target class after placing the patch. I keep the patch values in [0,1] by clamping after each step. If the model is untrained (no weights), numbers will look random; I should ensure the pretrained weights downloaded for meaningful results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7801fa31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training loop\n",
    "target_idx = int(TARGET)\n",
    "steps = 250 if device.type=='cuda' else 120  # keep it reasonable on CPU\n",
    "lr = 0.08\n",
    "patch_side = 64\n",
    "\n",
    "patch = torch.rand(3, patch_side, patch_side, device=device, requires_grad=True)\n",
    "opt = torch.optim.Adam([patch], lr=lr)\n",
    "\n",
    "mean = torch.tensor([0.485, 0.456, 0.406], device=device).view(1,3,1,1)\n",
    "std  = torch.tensor([0.229, 0.224, 0.225], device=device).view(1,3,1,1)\n",
    "\n",
    "loss_hist = []\n",
    "\n",
    "for t in range(steps):\n",
    "    opt.zero_grad()\n",
    "    # place the patch on slightly jittered copies to add robustness\n",
    "    imgs01 = batch01.clone()\n",
    "    adv01 = place_patch(imgs01, patch, 0.18, 0.32)\n",
    "    # normalize for model\n",
    "    adv = (adv01 - mean) / std\n",
    "    logits = model(adv)\n",
    "    # targeted loss: encourage target logit high\n",
    "    target = torch.full((adv.shape[0],), target_idx, dtype=torch.long, device=device)\n",
    "    loss = F.cross_entropy(logits, target) * 1.0\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    with torch.no_grad():\n",
    "        patch.clamp_(0,1)\n",
    "    loss_hist.append(float(loss.item()))\n",
    "    if (t+1) % max(1, steps//10) == 0:\n",
    "        print(f'step {t+1}/{steps}  loss={loss.item():.4f}')\n",
    "\n",
    "plt.figure(); plt.plot(loss_hist); plt.title('loss'); plt.xlabel('step'); plt.ylabel('CE'); plt.show()\n",
    "\n",
    "# show learned patch and also save a high-res version for printing\n",
    "show_tensor_img(patch, title='learned patch (view)')\n",
    "save_tensor_img(F.interpolate(patch.unsqueeze(0), size=(700,700), mode='nearest'), OUT / 'patch_print.png')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44fa0072",
   "metadata": {},
   "source": [
    "Evaluate\n",
    "\n",
    "I place the patch at random positions on each image and report the top-5 predictions. I also compute targeted success rate (whether the target class is ranked top-1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02358bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def eval_with_patch(images01, patch, trials=8):\n",
    "    N = images01.shape[0]\n",
    "    top1_hits = 0\n",
    "    all_reports = []\n",
    "    for r in range(trials):\n",
    "        adv01 = place_patch(images01, patch, 0.2, 0.32)\n",
    "        adv = (adv01 - mean) / std\n",
    "        logits = model(adv)\n",
    "        probs, idxs = topk_preds(logits, k=5)\n",
    "        for i in range(N):\n",
    "            hit = (idxs[i,0] == target_idx)\n",
    "            if hit: top1_hits += 1\n",
    "            all_reports.append((i, probs[i], idxs[i]))\n",
    "    sr = top1_hits / (N * trials + 1e-9)\n",
    "    return sr, all_reports\n",
    "\n",
    "sr, reports = eval_with_patch(batch01, patch, trials=6)\n",
    "print(f'targeted top-1 success rate over random placements: {sr:.3f}')\n",
    "# visualize a single random placement\n",
    "adv01 = place_patch(batch01, patch, 0.24, 0.32)\n",
    "show_tensor_img(adv01, title='example patched image (first item)')\n",
    "save_tensor_img(adv01, OUT / 'example_patched.png')\n",
    "\n",
    "# show predictions for the first image (last trial)\n",
    "with torch.no_grad():\n",
    "    adv = (adv01 - mean) / std\n",
    "    logits = model(adv)\n",
    "probs, idxs = topk_preds(logits, k=5)\n",
    "i = 0\n",
    "print('patched first image top-5:')\n",
    "for p, idx in zip(probs[i], idxs[i]):\n",
    "    name = IMAGENET_CLASSES[idx] if idx < len(IMAGENET_CLASSES) else f'class_{idx}'\n",
    "    print(f'  {float(p):.4f} -> {idx}: {name}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7312d766",
   "metadata": {},
   "source": [
    "Sticker disguise\n",
    "\n",
    "I turn the patch into a circular sticker by applying a round alpha mask, then place it. I also export a print sheet for this version. This is my creative extension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e3891ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def circular_mask_like(p):\n",
    "    _, H, W = p.shape\n",
    "    y, x = torch.meshgrid(torch.arange(H, device=p.device), torch.arange(W, device=p.device), indexing='ij')\n",
    "    y = (y - H/2) / (H/2)\n",
    "    x = (x - W/2) / (W/2)\n",
    "    r = torch.sqrt(x*x + y*y)\n",
    "    m = (r <= 1.0).float().unsqueeze(0)  # [1,H,W]\n",
    "    # soften the edge\n",
    "    band = (r>0.95) & (r<=1.0)\n",
    "    m[0, band] = (1.0 - (r[band]-0.95)/0.05).float()\n",
    "    return m\n",
    "\n",
    "@torch.no_grad()\n",
    "def apply_mask(p, m):\n",
    "    return p * m + (0.0) * (1-m)\n",
    "\n",
    "mask_circ = circular_mask_like(patch)\n",
    "sticker = apply_mask(patch, mask_circ).clamp(0,1)\n",
    "show_tensor_img(sticker, title='sticker patch')\n",
    "\n",
    "# place and evaluate once\n",
    "adv01_sticker = place_patch(batch01, sticker, 0.24, 0.34)\n",
    "show_tensor_img(adv01_sticker, title='example sticker placement')\n",
    "save_tensor_img(F.interpolate(sticker.unsqueeze(0), size=(700,700), mode='nearest'), OUT / 'sticker_patch_print.png')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f3df3d0",
   "metadata": {},
   "source": [
    "Combine two patches\n",
    "\n",
    "I train a second small patch for another target and paste both. This tests what happens when two objectives mix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d198c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "SECOND_TARGET_KEYWORD = 'banana'\n",
    "SECOND_TARGET_INDEX = None\n",
    "SECOND_TARGET = resolve_target_index(SECOND_TARGET_KEYWORD, SECOND_TARGET_INDEX)\n",
    "\n",
    "steps2 = 160 if device.type=='cuda' else 90\n",
    "patch2 = torch.rand(3, 48, 48, device=device, requires_grad=True)\n",
    "opt2 = torch.optim.Adam([patch2], lr=0.08)\n",
    "for t in range(steps2):\n",
    "    opt2.zero_grad()\n",
    "    imgs01 = batch01.clone()\n",
    "    adv01 = place_patch(imgs01, patch2, 0.12, 0.22)\n",
    "    adv = (adv01 - mean) / std\n",
    "    logits = model(adv)\n",
    "    target2 = torch.full((adv.shape[0],), int(SECOND_TARGET), dtype=torch.long, device=device)\n",
    "    loss = F.cross_entropy(logits, target2)\n",
    "    loss.backward()\n",
    "    opt2.step()\n",
    "    with torch.no_grad():\n",
    "        patch2.clamp_(0,1)\n",
    "    if (t+1) % max(1, steps2//5) == 0:\n",
    "        print(f'second patch step {t+1}/{steps2}')\n",
    "\n",
    "# combine by placing both\n",
    "def place_two(images01, p1, p2):\n",
    "    tmp = place_patch(images01, p1, 0.20, 0.28)\n",
    "    out = place_patch(tmp, p2, 0.12, 0.20)\n",
    "    return out\n",
    "\n",
    "adv01_combo = place_two(batch01, patch, patch2)\n",
    "show_tensor_img(adv01_combo, title='two patches combined (first image)')\n",
    "save_tensor_img(adv01_combo, OUT / 'combo_patched.png')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97aff813",
   "metadata": {},
   "source": [
    "Secret message with a series of patches\n",
    "\n",
    "I put a row of small patches and encode a short message by rotation: 0°=0, 90°=1. I save a sheet to print. Anyone who knows the rule can read the bits from left to right. This is just for fun and to meet the requirement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4145c405",
   "metadata": {},
   "outputs": [],
   "source": [
    "msg = '1011001'  # I can change this to any bit string\n",
    "tile = F.interpolate(patch.unsqueeze(0), size=(80,80), mode='nearest')[0].detach().cpu()\n",
    "tiles = []\n",
    "for b in msg:\n",
    "    im = transforms.ToPILImage()(tile)\n",
    "    if b == '1':\n",
    "        im = im.rotate(90, expand=True).resize((80,80))\n",
    "    tiles.append(im)\n",
    "\n",
    "# compose a row\n",
    "W = 20 + len(tiles)*(80+12)\n",
    "H = 120\n",
    "sheet = Image.new('RGB', (W, H), (255,255,255))\n",
    "x = 10\n",
    "for im in tiles:\n",
    "    sheet.paste(im, (x, 20))\n",
    "    x += 80 + 12\n",
    "\n",
    "sheet_path = OUT / 'secret_message_sheet.png'\n",
    "sheet.save(sheet_path)\n",
    "display(sheet)\n",
    "print('saved', sheet_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f7a7d8",
   "metadata": {},
   "source": [
    "What I will bring to class\n",
    "\n",
    "1) a color print of `outputs/patch_print.png` (or `sticker_patch_print.png` if I prefer the circular version).  \n",
    "2) the GitHub repo with this notebook and the outputs folder.  \n",
    "3) I will demo with the example images. If I use my own photos, I will add them in the `raw_images` folder or upload in Colab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "208de154",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Artifacts saved in:', OUT)\n",
    "print('\\n'.join([p.name for p in OUT.glob('*')]))\n",
    "\n",
    "# simple check: ensure files exist so I know what to print\n",
    "assert (OUT / 'patch_print.png').exists(), 'patch_print.png missing'\n",
    "print('ready to go ✅')\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
